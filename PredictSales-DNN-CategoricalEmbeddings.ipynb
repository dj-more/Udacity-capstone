{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Predict Future Sales\n",
    "## Using Deep Neural Net \n",
    "## With Categorical Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "0  02.01.2013               0       59    22154      999.00           1.0\n",
       "1  03.01.2013               0       25     2552      899.00           1.0\n",
       "2  05.01.2013               0       25     2552      899.00          -1.0\n",
       "3  06.01.2013               0       25     2554     1709.05           1.0\n",
       "4  15.01.2013               0       25     2555     1099.00           1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "stdout = sys.stdout\n",
    "sales_train = pd.read_csv(\"/Users/djmore/Udacity/machine-learning/projects/capstone/sales_train.csv\", sep =',')\n",
    "\n",
    "sales_data = pd.DataFrame(sales_train)\n",
    "items = pd.read_csv('/Users/djmore/Udacity/machine-learning/projects/capstone/items.csv')\n",
    "item_categories = pd.read_csv('/Users/djmore/Udacity/machine-learning/projects/capstone/item_categories.csv')\n",
    "shops = pd.read_csv('/Users/djmore/Udacity/machine-learning/projects/capstone/shops.csv')\n",
    "\n",
    "\n",
    "items_data = pd.DataFrame(items)\n",
    "item_categories_data = pd.DataFrame(item_categories)\n",
    "shops_data = pd.DataFrame(shops)\n",
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there are blank rows or null values in any data elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              False\n",
       "date_block_num    False\n",
       "shop_id           False\n",
       "item_id           False\n",
       "item_price        False\n",
       "item_cnt_day      False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sales_data.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe data, gather basic stats and check for invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shops               - 60\n",
      "Item Categories     - 84\n",
      "Items               - 22170\n",
      "Median item price   - 399.0\n",
      "Min item price      - -1.0\n",
      "Max item price      - 307980.0\n",
      "Total Rows          - 2935849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Shops               - {}'.format(shops_data['shop_id'].count()))\n",
    "print('Item Categories     - {}'.format(items_data['item_category_id'].nunique()))\n",
    "print('Items               - {}'.format(items_data['item_id'].count()))\n",
    "print('Median item price   - {}'.format(sales_data['item_price'].median()))\n",
    "print('Min item price      - {}'.format(sales_data['item_price'].min()))\n",
    "print('Max item price      - {}'.format(sales_data['item_price'].max()))\n",
    "print('Total Rows          - {}'.format(sales_data['shop_id'].count()))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative item counts may indicate either returns or buy one get one promo. \n",
    "### Analyze which item_category and item_names have negative item counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Item Count = 7356\n",
      "Negative Item Price = 1\n"
     ]
    }
   ],
   "source": [
    "print('Negative Item Count = {}'.format((sales_data[sales_data['item_cnt_day'] < 0])['item_cnt_day'].count()))\n",
    "print('Negative Item Price = {}'.format((sales_data[sales_data['item_price'] < 0])['item_price'].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Clean up sales data\n",
    "### Remove negative sales values from data\n",
    "#### For the purpose of this exercise we will remove all returns data i.e. negative item_price rows.\n",
    "#### Negative values under item_cnt_day may indicate either a return or promo such as buy one get one free. \n",
    "#### Since we have not been any given any information and there are only handful of rows we will avoid the complexity of \n",
    "#### negative values by removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data = sales_data[sales_data.item_cnt_day > 0] ## Remove rows that have negative item_cnt_day\n",
    "sales_data = sales_data[sales_data.item_price > 0]   #  Remove rows that have negative item_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Item Count = 7356\n",
      "Negative Item Price = 0\n"
     ]
    }
   ],
   "source": [
    "print('Negative Item Count = {}'.format((sales_data[sales_data['item_cnt_day'] < 0])['item_cnt_day'].count()))\n",
    "print('Negative Item Price = {}'.format((sales_data[sales_data['item_price'] < 0])['item_price'].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Future Sales\n",
    "# Using Deep Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break down date column into individual features\n",
    "### Year, Month, Day, DayofYear, WeekOfYear, DayOfWeek, Quarter\n",
    "#### This will help us capture weekly, monthly, quarterly and yearly seasonality in the sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date field to datetime field in pandas\n",
    "sales_data['date'] = pd.to_datetime(sales_data['date'])\n",
    "\n",
    "# Extract out date features\n",
    "sales_data['year'] = sales_data['date'].dt.year\n",
    "sales_data['month'] = sales_data['date'].dt.month\n",
    "sales_data['day'] = sales_data['date'].dt.day\n",
    "\n",
    "sales_data['dayofyear'] = sales_data['date'].dt.dayofyear\n",
    "sales_data['weekofyear'] = sales_data['date'].dt.weekofyear\n",
    "sales_data['dayofweek'] = sales_data['date'].dt.dayofweek\n",
    "sales_data['quarter'] = sales_data['date'].dt.quarter\n",
    "\n",
    "# Sort data in ascending order of time series - year, month,and day\n",
    "sales_data.sort_values(['date_block_num','date'], ascending=[True,True],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.drop(['date'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7554</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18976</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18284</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18320</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18329</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19367</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_block_num  shop_id  item_id  item_price  item_cnt_day  year  month  \\\n",
       "7554               0       19    18976       399.0           1.0  2013      1   \n",
       "7644               0       19    18284       199.0           1.0  2013      1   \n",
       "7646               0       19    18320       199.0           1.0  2013      1   \n",
       "7647               0       19    18329       299.0           1.0  2013      1   \n",
       "7694               0       19    19367       399.0           1.0  2013      1   \n",
       "\n",
       "      day  dayofyear  weekofyear  dayofweek  quarter  \n",
       "7554    1          1           1          1        1  \n",
       "7644    1          1           1          1        1  \n",
       "7646    1          1           1          1        1  \n",
       "7647    1          1           1          1        1  \n",
       "7694    1          1           1          1        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data['shop_id'] = pd.Categorical(sales_data['shop_id'])\n",
    "sales_data['item_id'] = pd.Categorical(sales_data['item_id'])\n",
    "\n",
    "sales_data['year'] = pd.Categorical(sales_data['year'])\n",
    "sales_data['month'] = pd.Categorical(sales_data['month'])\n",
    "\n",
    "sales_data['day'] = pd.Categorical(sales_data['day'])\n",
    "sales_data['dayofyear'] = pd.Categorical(sales_data['dayofyear'])\n",
    "\n",
    "sales_data['weekofyear'] = pd.Categorical(sales_data['weekofyear'])\n",
    "sales_data['dayofweek'] = pd.Categorical(sales_data['dayofweek'])\n",
    "sales_data['quarter'] = pd.Categorical(sales_data['quarter'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Net "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the model to run raw daily sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Numerical columns item_price and item_cnt_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train-Test-Split Data\n",
    "###  We will use \n",
    "  - First 31 months of data as training data \n",
    "  - 32nd months data as validation data\n",
    "  - 33rd month data as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sales_data[sales_data.date_block_num < 28]\n",
    "y_train = X_train['item_cnt_day']\n",
    "del X_train['item_cnt_day']\n",
    "\n",
    "X_val = sales_data[(sales_data.date_block_num >= 28) & (sales_data.date_block_num <= 32)] \n",
    "y_val = X_val['item_cnt_day']\n",
    "del X_val['item_cnt_day']\n",
    "\n",
    "X_test = sales_data[sales_data.date_block_num == 33]\n",
    "y_test = X_test['item_cnt_day']\n",
    "del X_test['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Date Block Num from    0 to 27\n",
      "Validation Date Block Num from  28 to 32\n",
      "Testing Date Block Num from     33\n"
     ]
    }
   ],
   "source": [
    "print('Training Date Block Num from    0 to 27')\n",
    "print('Validation Date Block Num from  28 to 32')\n",
    "print('Testing Date Block Num from     33')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "#### With Embeddings for daily sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djmore/anaconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 11, 200)           80000000  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 6603      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 80,006,619\n",
      "Trainable params: 80,006,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# Embedding\n",
    "max_features = 400000\n",
    "maxlen = X_train.shape[1]\n",
    "embedding_size = 200\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(3, activation=None))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation=None))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53514, 11)\n",
      "(53514,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.26845147360484 1.3464223528432264\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "\n",
    "mae,a = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(mae,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2610003 samples, validate on 272331 samples\n",
      "Epoch 1/20\n",
      "2610003/2610003 [==============================] - 415s 159us/step - loss: 4.8592 - mean_absolute_error: 0.7039 - val_loss: 11.6792 - val_mean_absolute_error: 0.4448\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 11.67916, saving model to predictsales.model.best.hdf5\n",
      "Epoch 2/20\n",
      "2610003/2610003 [==============================] - 398s 153us/step - loss: 4.4721 - mean_absolute_error: 0.5408 - val_loss: 11.6675 - val_mean_absolute_error: 0.4525\n",
      "\n",
      "Epoch 00002: val_loss improved from 11.67916 to 11.66746, saving model to predictsales.model.best.hdf5\n",
      "Epoch 3/20\n",
      "2610003/2610003 [==============================] - 359s 137us/step - loss: 4.3466 - mean_absolute_error: 0.4703 - val_loss: 11.7011 - val_mean_absolute_error: 0.4413\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 11.66746\n",
      "Epoch 4/20\n",
      "2610003/2610003 [==============================] - 549s 210us/step - loss: 4.2866 - mean_absolute_error: 0.4270 - val_loss: 11.6503 - val_mean_absolute_error: 0.4355\n",
      "\n",
      "Epoch 00004: val_loss improved from 11.66746 to 11.65027, saving model to predictsales.model.best.hdf5\n",
      "Epoch 5/20\n",
      "2610003/2610003 [==============================] - 356s 137us/step - loss: 4.2480 - mean_absolute_error: 0.4131 - val_loss: 11.6334 - val_mean_absolute_error: 0.4247\n",
      "\n",
      "Epoch 00005: val_loss improved from 11.65027 to 11.63340, saving model to predictsales.model.best.hdf5\n",
      "Epoch 6/20\n",
      "2610003/2610003 [==============================] - 351s 135us/step - loss: 4.2245 - mean_absolute_error: 0.4217 - val_loss: 11.6332 - val_mean_absolute_error: 0.4614\n",
      "\n",
      "Epoch 00006: val_loss improved from 11.63340 to 11.63317, saving model to predictsales.model.best.hdf5\n",
      "Epoch 7/20\n",
      "2610003/2610003 [==============================] - 364s 139us/step - loss: 4.2313 - mean_absolute_error: 0.4321 - val_loss: 11.5996 - val_mean_absolute_error: 0.4676\n",
      "\n",
      "Epoch 00007: val_loss improved from 11.63317 to 11.59960, saving model to predictsales.model.best.hdf5\n",
      "Epoch 8/20\n",
      "2610003/2610003 [==============================] - 358s 137us/step - loss: 4.2182 - mean_absolute_error: 0.4347 - val_loss: 11.6450 - val_mean_absolute_error: 0.5093\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 11.59960\n",
      "Epoch 9/20\n",
      "2610003/2610003 [==============================] - 477s 183us/step - loss: 4.2204 - mean_absolute_error: 0.4362 - val_loss: 11.6240 - val_mean_absolute_error: 0.5250\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 11.59960\n",
      "Epoch 10/20\n",
      "2610003/2610003 [==============================] - 570s 218us/step - loss: 4.2193 - mean_absolute_error: 0.4384 - val_loss: 11.7284 - val_mean_absolute_error: 0.6158\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 11.59960\n",
      "Epoch 11/20\n",
      "2610003/2610003 [==============================] - 591s 226us/step - loss: 4.2190 - mean_absolute_error: 0.4376 - val_loss: 11.7381 - val_mean_absolute_error: 0.6144\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 11.59960\n",
      "Epoch 12/20\n",
      "2610003/2610003 [==============================] - 648s 248us/step - loss: 4.2078 - mean_absolute_error: 0.4388 - val_loss: 11.8136 - val_mean_absolute_error: 0.6581\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 11.59960\n",
      "Epoch 13/20\n",
      "2610003/2610003 [==============================] - 618s 237us/step - loss: 4.2056 - mean_absolute_error: 0.4394 - val_loss: 11.7927 - val_mean_absolute_error: 0.6275\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 11.59960\n",
      "Epoch 14/20\n",
      "2610003/2610003 [==============================] - 501s 192us/step - loss: 4.1918 - mean_absolute_error: 0.4392 - val_loss: 11.8357 - val_mean_absolute_error: 0.6395\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 11.59960\n",
      "Epoch 15/20\n",
      "2610003/2610003 [==============================] - 399s 153us/step - loss: 4.1899 - mean_absolute_error: 0.4391 - val_loss: 11.9499 - val_mean_absolute_error: 0.6937\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 11.59960\n",
      "Epoch 16/20\n",
      "2610003/2610003 [==============================] - 428s 164us/step - loss: 4.1902 - mean_absolute_error: 0.4382 - val_loss: 11.8577 - val_mean_absolute_error: 0.7078\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 11.59960\n",
      "Epoch 17/20\n",
      "2610003/2610003 [==============================] - 431s 165us/step - loss: 4.1912 - mean_absolute_error: 0.4375 - val_loss: 11.9380 - val_mean_absolute_error: 0.6845\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 11.59960\n",
      "Epoch 18/20\n",
      "2610003/2610003 [==============================] - 407s 156us/step - loss: 4.1866 - mean_absolute_error: 0.4370 - val_loss: 11.9307 - val_mean_absolute_error: 0.6819\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 11.59960\n",
      "Epoch 19/20\n",
      "2610003/2610003 [==============================] - 414s 159us/step - loss: 4.1867 - mean_absolute_error: 0.4358 - val_loss: 11.9602 - val_mean_absolute_error: 0.7313\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 11.59960\n",
      "Epoch 20/20\n",
      "2610003/2610003 [==============================] - 428s 164us/step - loss: 4.2049 - mean_absolute_error: 0.4341 - val_loss: 11.9842 - val_mean_absolute_error: 0.6918\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 11.59960\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='predictsales.model.best.hdf5', verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=10000, epochs=20, validation_data=(X_val, y_val), \n",
    "                 callbacks=[checkpointer],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Classification Accuracy on the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('predictsales.model.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Model Loss or Accuracy on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.26845147360484 0.594486800222318\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "\n",
    "mse,a = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(mae,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 95.0753490439377\n",
      "RMSE: 9.750658903065869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "meanSquaredError=mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", meanSquaredError)\n",
    "\n",
    "rootMeanSquaredError = sqrt(meanSquaredError)\n",
    "print(\"RMSE:\", rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sales in 34th month were 71056.0 and model predicted 68253.0\n"
     ]
    }
   ],
   "source": [
    "print('Actual sales in 34th month were {} and model predicted {}'.format(y_test.sum(),round(y_pred.sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
